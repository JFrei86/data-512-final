{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Motivation  \n",
    "\n",
    "Multiple studies have suggested that the language we use in hiring influences the audience we are trying to reach and in turn influences the individuals who are hired. The goal for this project is to identify linguistic patterns that have bias in online job postings. The scope of this project is to reproduce research to determine if male/female dominated jobs container gender specific language that could deter applicants. \n",
    "\n",
    "# Related Work \n",
    "\n",
    "Hiring practices are what drives economic equity and gender equality. As such recruiters and hiring managers are gatekeepers with the opportunity to affect the people we work with. However, multiple people have been looking at a part of the pipeline which is often ignored: Both companies and individuals have looked at this problem before including [Textio](https://textio.com/blog/avoiding-harmful-language-in-hiring-content/34152146534) and [Jieyu Zhao](https://arxiv.org/abs/1707.09457). Textio builds products to identify writing that contains strong tone that may affect the audience job description authors are trying to reach out to. Jieyu is a Microsoft fellowship recipient who has published numerous papers on identifying gender bias in corpora and how to compensate when training models. \n",
    "\n",
    "[University of Waterloo and Duke](https://www.paycor.com/resource-center/gender-discrimination-in-job-descriptions) also conducted a study of 96 individuals who looked at 6 job postings where 2 were written using terms and phrases that were considered “more masculine” and 2 were written using “more feminine” terms. The remaining two were neutral in wording. The conclusion of the study was that women were more likely not to apply to the positions that contained more masculine phrasing. \n",
    "\n",
    "# Data  \n",
    "\n",
    "The dataset consists of 30,000 US job postings that were posted publicly through the website Indeed. The data was extracted by a web content scraping company called PromptCloud and licensed as Public Domain.  \n",
    "\n",
    "The data consists of job posts from August 1st, 2019 through October 31st, 2019. Each job post contains a natural language column for job description. The dataset is originally from a data repository [(link)](https://data.world/promptcloud/indeed-job-posting-dataset)  \n",
    "\n",
    "It will be useful for comparing the terms used in the job post with the job title.  \n",
    "\n",
    "I do not believe there are ethical concerns as this dataset was published publicly and the original data itself was available publicly on Indeed's website.  \n",
    "\n",
    "# Research Questions \n",
    "\n",
    "1. What are the most frequently used words that are used in job postings on this dataset? Is there anything that sticks out or seems like it may not generalize about job postings outside of the US? Could this introduce a bias if used outside of the US? \n",
    "\n",
    "2. What is the distribution of different job titles on this dataset? How many are considered stereotypically masculine or feminine? \n",
    "\n",
    "3. Is there a difference in the mean number of masculine and feminine terms for jobs that are sterrotypically more masculine and feminine respectively? \n",
    "\n",
    "# Methodology \n",
    "\n",
    "To perform this analysis, I will be using a set of terms that were defined by the University of Waterloo and Duke as traditionally masculine and feminine phrases respectively. After preprocessing the text in the job descriptions, I want to compute if the mean number of traditionally masculine phrases is different for roles using t-tests. I would like to perform this on the larger dataset for individual categories of positions: \n",
    "\n",
    "- Engineering Roles \n",
    "- Administrative Roles \n",
    "- Healthcare Roles "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}